@article{Goel2021,
   abstract = {Accurate identification of siblings through face recognition is a challenging task. This is predominantly because of the high degree of similarities among the faces of siblings. In this study, we investigate the use of state-of-the-art deep learning face recognition models to evaluate their capacity for discrimination between sibling faces using various similarity indices. The specific models examined for this purpose are FaceNet, VGGFace, VGG16, and VGG19. For each pair of images provided, the embeddings have been calculated using the chosen deep learning model. Five standard similarity measures, namely, cosine similarity, Euclidean distance, structured similarity, Manhattan distance, and Minkowski distance, are used to classify images looking for their identity on the threshold defined for each of the similarity measures. The accuracy, precision, and misclassification rate of each model are calculated using standard confusion matrices. Four different experimental datasets for full-frontal-face, eyes, nose, and forehead of sibling pairs are constructed using publicly available HQf subset of the SiblingDB database. The experimental results show that the accuracy of the chosen deep learning models to distinguish siblings based on the full-frontal-face and cropped face areas vary based on the face area compared. It is observed that VGGFace is best while comparing the full-frontal-face and eyes—the accuracy of classification being with more than 95% in this case. However, its accuracy degrades significantly when the noses are compared, while FaceNet provides the best result for classification based on the nose. Similarly, VGG16 and VGG19 are not the best models for classification using the eyes, but these models provide favorable results when foreheads are compared.},
   author = {Rita Goel and Irfan Mehmood and Hassan Ugail},
   doi = {10.3390/S21155068},
   issn = {14248220},
   issue = {15},
   journal = {Sensors},
   keywords = {Face recognition,FaceNet,Sibling recognition,VGG16,VGG19,VGGFace},
   month = {8},
   pmid = {34372306},
   publisher = {MDPI AG},
   title = {A study of deep learning-based face recognition models for sibling identification},
   volume = {21},
   year = {2021},
}

@article{CombiningCNN,
   abstract = {Recently, a common starting point for solving complex unsupervised image classification tasks is to use generic features, extracted with deep Convolutional Neural Networks (CNN) pretrained on a large and versatile dataset (ImageNet). However, in most research, the CNN architecture for feature extraction is chosen arbitrarily, without justification. This paper aims at providing insight on the use of pretrained CNN features for image clustering (IC). First, extensive experiments are conducted and show that, for a given dataset, the choice of the CNN architecture for feature extraction has a huge impact on the final clustering. These experiments also demonstrate that proper extractor selection for a given IC task is difficult. To solve this issue, we propose to rephrase the IC problem as a multi-view clustering (MVC) problem that considers features extracted from different architectures as different “views” of the same data. This approach is based on the assumption that information contained in the different CNN may be complementary, even when pretrained on the same data. We then propose a multi-input neural network architecture that is trained end-to-end to solve the MVC problem effectively. This approach is tested on nine natural image datasets, and produces state-of-the-art results for IC.},
   author = {Joris Guérin and Stéphane Thiery and Eric Nyiri and Olivier Gibaru and Byron Boots},
   doi = {10.1016/J.NEUCOM.2020.10.068},
   issn = {18728286},
   journal = {Neurocomputing},
   keywords = {Image clustering,Multi-View clustering,Transfer clustering},
   month = {1},
   pages = {551-571},
   publisher = {Elsevier B.V.},
   title = {Combining pretrained CNN feature extractors to enhance clustering of complex natural images},
   volume = {423},
   year = {2021},
}

@article{IECNN,
   abstract = {In the field of face recognition, similar face recognition is difficult due to the high degree of similarity of the face structure. The following two factors are needed to make progress in this field: (i) the availability of large scale similar face training datasets, and (ii) a fine-grained face recognition method. With the above factors fulfilled, we make two contributions. First, we show how a large scale similar face dataset (SFD) can be assembled by a combination of automation and human in the loop, and divide the dataset into five grades according to different degrees of similarity. Second, a new fine-grained face feature extraction method is proposed to solve this problem using the attention mechanism which combines the Internal Features and External Features. The Labeled Faces in the Wild (LFW) database, CASIA-WebFace and similar face dataset (SFD) were selected for experiments. It turns out that the true positive rate is improved by 1.94 - 5.66% and the recognition accuracy rate improved by 2.08 - 5.8% for the LFW and CASIA-WebFace database, respectively. Meanwhile for SFD, the recognition accuracy rate improved by 18.80 - 35.84%.},
   author = {An Ping Song and Qian Hu and Xue Hai Ding and Xin Yi Di and Zi Heng Song},
   doi = {10.1109/ACCESS.2020.2978938},
   issn = {21693536},
   journal = {IEEE Access},
   keywords = {Artificial neural networks,Computer vision,Face recognition,Image databases,Machine learning},
   pages = {45244-45253},
   publisher = {Institute of Electrical and Electronics Engineers Inc.},
   title = {Similar Face Recognition Using the IE-CNN Model},
   volume = {8},
   year = {2020},
}

@article{Yang2018,
   abstract = {In the big data era, the data are generated from different sources or observed from different views. These data are referred to as multi-view data. Unleashing the power of knowledge in multi-view data is very important in big data mining and analysis. This calls for advanced techniques that consider the diversity of different views, while fusing these data. Multi-view Clustering (MvC) has attracted increasing attention in recent years by aiming to exploit complementary and consensus information across multiple views. This paper summarizes a large number of multi-view clustering algorithms, provides a taxonomy according to the mechanisms and principles involved, and classifies these algorithms into five categories, namely, co-training style algorithms, multi-kernel learning, multiview graph clustering, multi-view subspace clustering, and multi-task multi-view clustering. Therein, multi-view graph clustering is further categorized as graph-based, network-based, and spectral-based methods. Multi-view subspace clustering is further divided into subspace learning-based, and non-negative matrix factorization-based methods. This paper does not only introduce the mechanisms for each category of methods, but also gives a few examples for how these techniques are used. In addition, it lists some publically available multi-view datasets. Overall, this paper serves as an introductory text and survey for multi-view clustering.},
   author = {Yan Yang and Hao Wang},
   doi = {10.26599/BDMA.2018.9020003},
   issn = {20960654},
   issue = {2},
   journal = {Big Data Mining and Analytics},
   keywords = {Co-training,Graph clustering,Multi-kernel learning,Multi-task learning,Multi-view clustering,Non-negative matrix factorization,Subspace clustering,Subspace learning},
   month = {6},
   pages = {83-107},
   publisher = {Tsinghua University Press},
   title = {Multi-view clustering: A survey},
   volume = {1},
   year = {2018},
}
